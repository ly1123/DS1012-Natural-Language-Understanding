{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1, DS-GA 1012, Spring 2019\n",
    "\n",
    "## Due Feburary 13, 2019 at 2pm (ET)\n",
    "\n",
    "Download the data zip `DS-GA1012-hw1-data.zip`. Complete the following questions in the notebook and submit your completed notebook on NYU Classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from numpy.linalg import svd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sst(data_file):\n",
    "    with open(data_file, 'r') as data_fh:\n",
    "        data_fh.readline() # skip the header\n",
    "        data = [r.split('\\t')[1] for r in data_fh.readlines()]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploring effect of context size [30 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We face many implicit and explicit design decisions in creating distributional word representations. For example, in lecture and in lab, we created word vectors using a co-occurence matrix built on neighboring pairs of words. We might suspect, however, that we can get more signal of word similarity by considering larger contexts than pairs of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__a__. Write `build_cooccurrence_matrix`, which generates the co-occurence matrix for a window of arbitrary size and for the vocabulary of `max_vocab_size` most frequent words. Feel free to modify the code used in lab [10 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "def build_cooccurrence_matrix(data, max_vocab_size=20000, context_size =1):\n",
    "    \"\"\" \n",
    "    \n",
    "    args:\n",
    "        - data: iterable where each item is a string sentence\n",
    "        - max_vocab_size: maximum vocabulary size\n",
    "        - context_size: window size\n",
    "        \n",
    "    returns:\n",
    "        - coocur_mat: co-occurrence matrix as a numpy array\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_token_frequencies():\n",
    "        tok2freq = defaultdict(int)\n",
    "        coocur_counts = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "        for datum in data:\n",
    "            tokens = datum.strip().split() # we'll use whitespace to tokenize\n",
    "            for i, tok in enumerate(tokens):\n",
    "                tok2freq[tok] += 1\n",
    "                coocur_counts[tok][tok] += 1\n",
    "                for c_size in range(1, context_size+1):\n",
    "                    if i < len(tokens) - c_size:\n",
    "                        coocur_counts[tok][tokens[i+c_size]] += 1\n",
    "                        coocur_counts[tokens[i+c_size]][tok] += 1\n",
    "#                     if i >= c_size:\n",
    "#                         coocur_counts[tok][tokens[i-c_size]] += 1\n",
    "#                         coocur_counts[tokens[i-c_size]][tok] += 1\n",
    "        return tok2freq, coocur_counts\n",
    "    \n",
    "    def prune_vocabulary(tok2freq, max_vocab_size):\n",
    "        \"\"\" Prune vocab by taking max_vocab_size most frequent words \"\"\"\n",
    "        tok_and_freqs = [(k, v) for k, v in tok2freq.items()]\n",
    "        tok_and_freqs.sort(key = lambda x: x[1], reverse=True) # sorts in-place\n",
    "        tok2idx = {tok: idx for idx, (tok, _) in enumerate(tok_and_freqs[:max_vocab_size])}\n",
    "        idx2tok = {idx: tok for tok, idx in tok2idx.items()}\n",
    "        return tok2idx, idx2tok\n",
    "    \n",
    "    def _build_coocurrence_mat(idx2tok, coocur_counts):\n",
    "        #mat = [[coocur_counts[idx2tok[i]][idx2tok[j]] for j in range(len(idx2tok))] for i in range(len(idx2tok))]\n",
    "        vocab_size = len(idx2tok)\n",
    "        mat = [[0 for _ in range(vocab_size)] for _ in range(vocab_size)]\n",
    "        \n",
    "#       mat = np.zeros(vocab_size, vocab_size) # create zero matrix with the vocab size  \n",
    "        for i in range(vocab_size - 1):\n",
    "            mat[i][i] = coocur_counts[idx2tok[i]][idx2tok[i]] # add the diagonal to the matrix\n",
    "            for j in range(i+1, vocab_size):\n",
    "                if coocur_counts[idx2tok[i]][idx2tok[j]]:\n",
    "                    mat[i][j] = coocur_counts[idx2tok[i]][idx2tok[j]]\n",
    "                    mat[j][i] = coocur_counts[idx2tok[i]][idx2tok[j]]\n",
    "#             for m in range(i):\n",
    "#                 if coocur_counts[idx2tok[m]][idx2tok[i]]:\n",
    "#                     mat[m][i] = coocur_counts[idx2tok[m]][idx2tok[i]]\n",
    "#                     mat[i][m] = coocur_counts[idx2tok[m]][idx2tok[i]]       \n",
    "        return np.array(mat)\n",
    "        \n",
    "    print(\"Counting words...\")\n",
    "    start_time = time.time()\n",
    "    tok2freq, coocur_counts = get_token_frequencies()\n",
    "    print(\"\\tFinished counting words in %.5f\" % (time.time() - start_time))\n",
    "\n",
    "    print(\"Pruning vocabulary...\")\n",
    "    tok2idx, idx2tok = prune_vocabulary(tok2freq, max_vocab_size)\n",
    "    start_time = time.time()\n",
    "    print(\"\\tFinished pruning vocabulary in %.5f\" % (time.time() - start_time))\n",
    "    \n",
    "    print(\"Building co-occurrence matrix...\")\n",
    "    print(\"Max vocabulary is: %d\" % (max_vocab_size))\n",
    "    print(\"Context size is: %d\" % (context_size))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    coocur_mat = _build_coocurrence_mat(idx2tok, coocur_counts)\n",
    "    print(\"\\tFinished building co-occurrence matrix in %.5f\" % (time.time() - start_time))\n",
    "    print('\\n')\n",
    "    return coocur_mat, tok2idx, idx2tok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your implementation of `build_cooccurrence_matrix` to generate the co-occurence matrix from the sentences of [SST](http://nlp.stanford.edu/~socherr/stanfordSentimentTreebank.zip) (file `datasetSentences.txt`) with `context_size=2` and `max_vocab_size=10000`. What is the co-occurrence count of the words \"the\" and \"end\"? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting words...\n",
      "\tFinished counting words in 0.52125\n",
      "Pruning vocabulary...\n",
      "\tFinished pruning vocabulary in 0.00000\n",
      "Building co-occurrence matrix...\n",
      "Max vocabulary is: 10000\n",
      "Context size is: 2\n",
      "\tFinished building co-occurrence matrix in 25.48546\n",
      "\n",
      "\n",
      "The co-occurence score of words \"the\" and \"end\" is:  98\n"
     ]
    }
   ],
   "source": [
    "data_file = 'datasetSentences.txt'\n",
    "data = load_sst(data_file)\n",
    "mat, tok2idx, idx2tok = build_cooccurrence_matrix(data, max_vocab_size=10000, context_size = 2)\n",
    "\n",
    "i, j = tok2idx['end'], tok2idx['the']\n",
    "print('The co-occurence score of words \"the\" and \"end\" is: ', int(mat[j][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__b__. Plot the effect of varying context size in $\\{1, 2, 3, 4\\}$ (leaving all the other settings the same) on the quality of the learned word embeddings, as measured by performance (Spearman correlation) on the word similarity dataset [MTurk-771](http://www2.mta.ac.il/~gideon/mturk771.html) between human judgments and cosine similarity of the learned word vectors (see lab). [12 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mturk data\n",
    "mturk = 'MTURK-771.csv'\n",
    "# mturk_data = pd.read_csv(mturk, header=None, names=[\"Word1\", \"Word2\", \"Similarity\"])\n",
    "\n",
    "def load_word_similarity_dataset(data_file):\n",
    "    with open(data_file, 'r') as data_fh:\n",
    "        raw_data = data_fh.readlines()\n",
    "    data = []\n",
    "    trgs = []\n",
    "    for datum in raw_data:\n",
    "        datum = datum.strip().split(',')\n",
    "        data.append((datum[0], datum[1]))\n",
    "        trgs.append(float(datum[2]))\n",
    "    return data, trgs\n",
    "\n",
    "test_data, test_trgs = load_word_similarity_dataset(mturk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize Matrix\n",
    "\n",
    "def prob_norm(u):\n",
    "    \"\"\"Normalize 1d np.array `u` into a probability distribution. Assumes \n",
    "    that all the members of `u` are positive. Returns a 1d np.array of \n",
    "    the same dimensionality as `u`.\"\"\"\n",
    "#     return u / np.sum(u)\n",
    "    return u / np.linalg.norm(u)\n",
    "\n",
    "def rowwise_norm_mat(mat):\n",
    "    return np.array([prob_norm(u) for u in mat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity Metrics\n",
    "def vector_length(u):\n",
    "    \"\"\"Length (L2) of the 1d np.array `u`. Returns a new np.array with the \n",
    "    same dimensions as `u`.\"\"\"\n",
    "    return np.sqrt(np.dot(u, u))\n",
    "\n",
    "def length_norm(u):\n",
    "    \"\"\"L2 norm of the 1d np.array `u`. Returns a float.\"\"\"\n",
    "    return u / vector_length(u)\n",
    "\n",
    "def cosine_similarity(u, v):        \n",
    "    \"\"\"Cosine similarity between 1d np.arrays `u` and `v`, which must have \n",
    "    the same dimensionality. Returns a float.\"\"\"\n",
    "    \n",
    "    return np.dot(u, v) / (vector_length(u) * vector_length(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting words...\n",
      "\tFinished counting words in 0.37704\n",
      "Pruning vocabulary...\n",
      "\tFinished pruning vocabulary in 0.00000\n",
      "Building co-occurrence matrix...\n",
      "Max vocabulary is: 10000\n",
      "Context size is: 1\n",
      "\tFinished building co-occurrence matrix in 24.92384\n",
      "\n",
      "\n",
      "Evaluated on 248 of 771 examples\n",
      "Counting words...\n",
      "\tFinished counting words in 0.50737\n",
      "Pruning vocabulary...\n",
      "\tFinished pruning vocabulary in 0.00000\n",
      "Building co-occurrence matrix...\n",
      "Max vocabulary is: 10000\n",
      "Context size is: 2\n",
      "\tFinished building co-occurrence matrix in 24.08728\n",
      "\n",
      "\n",
      "Evaluated on 248 of 771 examples\n",
      "Counting words...\n",
      "\tFinished counting words in 0.64099\n",
      "Pruning vocabulary...\n",
      "\tFinished pruning vocabulary in 0.00000\n",
      "Building co-occurrence matrix...\n",
      "Max vocabulary is: 10000\n",
      "Context size is: 3\n",
      "\tFinished building co-occurrence matrix in 24.00874\n",
      "\n",
      "\n",
      "Evaluated on 248 of 771 examples\n",
      "Counting words...\n",
      "\tFinished counting words in 0.78439\n",
      "Pruning vocabulary...\n",
      "\tFinished pruning vocabulary in 0.00000\n",
      "Building co-occurrence matrix...\n",
      "Max vocabulary is: 10000\n",
      "Context size is: 4\n",
      "\tFinished building co-occurrence matrix in 25.33605\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on 248 of 771 examples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x10aa71198>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "def evaluate_word_similarity(word_pairs, targets, mat, tok2idx):\n",
    "    \n",
    "    cal_scores = []\n",
    "    targs = []\n",
    "    idx = 0\n",
    "    \n",
    "    for (word1, word2), targ in zip(word_pairs, targets): # use zip to map values between two dataset wit\n",
    "        if word1 in tok2idx and word2 in tok2idx:\n",
    "            score = cosine_similarity(mat[tok2idx[word1]], mat[tok2idx[word2]])\n",
    "            cal_scores.append(score)\n",
    "            targs.append(targ)\n",
    "            idx +=1\n",
    "    # get the Spearman correlation        \n",
    "    corr, _ = spearmanr(targs, cal_scores, nan_policy = 'omit')\n",
    "    print(\"Evaluated on %d of %d examples\" % (idx, len(word_pairs)))\n",
    "    return corr\n",
    "\n",
    "    \n",
    "context_size = [1, 2, 3, 4]\n",
    "result = {}\n",
    "spearman_corr = {}\n",
    "output = []\n",
    "\n",
    "for size in context_size:\n",
    "    mat, tok2idx, _ = build_cooccurrence_matrix(data, max_vocab_size=10000, context_size = size)\n",
    "    result[size] = mat\n",
    "    norm_mat = rowwise_norm_mat(mat)\n",
    "    corr = evaluate_word_similarity(test_data, test_trgs, norm_mat, tok2idx)\n",
    "    output.append(corr)\n",
    "\n",
    "plt.plot(context_size, output)\n",
    "plt.title('Correlation of human judgments and cosine similarity of for each context size')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is shown on the graph, the correlation even goes to negative when context size is only 1.\n",
    "The Spearman Correlation between human judgments and cosine similarity is increased as the context size increases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context size</th>\n",
       "      <th>correlation score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.015468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.062675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.099013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.112812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   context size  correlation score\n",
       "0             1          -0.015468\n",
       "1             2           0.062675\n",
       "2             3           0.099013\n",
       "3             4           0.112812"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'context size': context_size, 'correlation score':output})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__c__. Briefly discuss the pros and cons of varying (i) the context size (ii) the vocabulary size (iii) using bigrams instead of unigrams (iv) using subword tokens instead of words. [8 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i) The Spearman Correlation between human judgments and cosine similarity is increased as the context size increases. As it is shown on the graph, the correlation even goes to negative when context size is only 1. When context size is larger, it may show more semantic information of the context, thus creates a more meaningful embedding for the words. \n",
    "\n",
    "pros: more semantic information between each words, possibly improve word embedding with more cooccurrence count\n",
    "\n",
    "cons: increase calcualtion cost, may include unnecessary information between two unrelated words with huge context size like 100, they may even not in a same paragraph! \n",
    "\n",
    "\n",
    "(ii) The Spearman Correlation between human judgments and cosine similarity could be increased with a larger vocabulary size because more information is provided for each word with higher dimension. However, a larger vocabulary doesn't necessary improve the performance. A larger vocabulary or dimension of each word would also add sparsity and cost to the calculation. \n",
    "\n",
    "pros: possibly provide more information for each words, can match up more words in the document.\n",
    "\n",
    "cons: increase calculation cost, introduce a higher dimension word embedding and higher sparsity as well.\n",
    "\n",
    "\n",
    "(iii) Unigrams vs. Bigrams\n",
    "\n",
    "Unigrams:\n",
    "\n",
    "pros: unigrams is straight-forward to measure the cooccurrence count between two single words. Easy to interpret, calculate and manipulate in matrix. \n",
    "\n",
    "cons: does not contain much information of short phrase like : \"American Express\", or \"Fedural Reserve\" comparing with bigrams.\n",
    "\n",
    "\n",
    "Bigrams:\n",
    "\n",
    "pros: potentially contain more inforamtion than unigram especially for short phrase like \"Star War\"\n",
    "\n",
    "cons: vocabulary size is much larger than unigrams with all combinations of two words. \n",
    "\n",
    "the cooccurrence matrix could be really sparsity with higher dimensions since it is harder for two bigrams to cooccur together. \n",
    "\n",
    "\n",
    "(iv) Subword tokens vs. Complete word\n",
    "\n",
    "Subword tokens:\n",
    "\n",
    "pros: By looking at subword token, like 'PowerShot'--> 'Power' and 'Shot' or 'AutoEncoder' --> 'Auto' and 'Encoder' understand more information within words.\n",
    "\n",
    "cons: introduce higher vocabulary size comparing with single words. Higher dimension also cause sparsity problem. The meaning of word could be changed after subtokenize. Like 'Understand' --> 'Under' and 'Stand'\n",
    "\n",
    "\n",
    "Complete word:\n",
    "\n",
    "pros: smaller size of vocabulary size, can maintain information of the whole word.\n",
    "\n",
    "cons: lack underlaying information of subword\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pointwise Mutual Information [20 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In lecture, we introduced __pointwise mutual information__ (PMI), which addresses the issue of normalization removing information about absolute magnitudes of counts. The PMI for word $\\times$ context pair $(w,c)$ is \n",
    "\n",
    "$$\\log\\left(\\frac{P(w,c)}{P(w) \\cdot P(c)}\\right)$$\n",
    "\n",
    "with $\\log(0) = 0$. This is a measure of how far that cell's value deviates from what we would expect given the row and column sums for that cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__a__. Implement `pmi`, a function which takes in a co-occurence matrix and returns the matrix with PMI normalization applied. [15 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PMI using unigram and bigram sum\n",
    "\n",
    "def pmi_1(mat):\n",
    "    \"\"\"Pointwise mutual information\n",
    "    \n",
    "    args:\n",
    "        - mat: 2d np.array to apply PMI\n",
    "        \n",
    "    returns:\n",
    "        - pmi_mat: matrix of same shape with PMI applied\n",
    "        \n",
    "    \"\"\"  \n",
    "    #total sum of unigram\n",
    "    unigram_sum = mat.diagonal().sum() # frequency of single word\n",
    "    \n",
    "    #total sum of bigram (w1, w2)\n",
    "    bi_mat = mat.copy()\n",
    "    np.fill_diagonal(bi_mat, 0) #replace diagonal with zero for bigram calculation\n",
    "    bigram_sum = (bi_mat.sum()/ 2)# here we assume its context size = 1\n",
    "    \n",
    "    pmi_mat = np.zeros_like(mat) \n",
    "    for i in range(mat.shape[0]):\n",
    "        for j in range(i+1, mat.shape[0]):\n",
    "            \n",
    "                p_w1w2 = mat[i][j]/ bigram_sum\n",
    "                p_w1 = mat[i][i] / unigram_sum\n",
    "                p_w2 = mat[j][j] / unigram_sum\n",
    "                if p_w1w2 == 0 or p_w1*p_w2 ==0 :\n",
    "                    pmi_score = 0\n",
    "                else:\n",
    "                    pmi_score = np.log(p_w1w2 / (p_w1*p_w2))\n",
    "                pmi_mat[i][j] = pmi_score\n",
    "                pmi_mat[j][i] = pmi_score\n",
    "    return pmi_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmi_2(mat):\n",
    "    \"\"\"Pointwise mutual information\n",
    "    \n",
    "    args:\n",
    "        - mat: 2d np.array to apply PMI\n",
    "        \n",
    "    returns:\n",
    "        - pmi_mat: matrix of same shape with PMI applied\n",
    "    \"\"\"    \n",
    "#     np.fill_diagonal(mat, 0)\n",
    "    total_sum = mat.sum()\n",
    "    \n",
    "    mat = mat/total_sum\n",
    "    #row sum of matrix\n",
    "    row_s = mat.sum(axis = 1)\n",
    "    #column sum of matrix\n",
    "    col_s = mat.sum(axis = 0)\n",
    "    \n",
    "    s1 = mat/col_s\n",
    "    s2 = s1/row_s[:, np.newaxis]\n",
    "    \n",
    "    #change the 0 input as 1 so that log(1) = 0\n",
    "    s2[s2 == 0] = 1\n",
    "    \n",
    "    return np.log(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply PMI to the co-occurence matrix computed above with `context_size=1`. What is the PMI between the words \"the\" and \"end\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting words...\n",
      "\tFinished counting words in 0.57446\n",
      "Pruning vocabulary...\n",
      "\tFinished pruning vocabulary in 0.00000\n",
      "Building co-occurrence matrix...\n",
      "Max vocabulary is: 10000\n",
      "Context size is: 1\n",
      "\tFinished building co-occurrence matrix in 25.35439\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mat, tok2idx, idx2tok = build_cooccurrence_matrix(data, max_vocab_size=10000, context_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram sum method: The PMI normalization score of words \"the\" and \"end\" is:  2.0\n"
     ]
    }
   ],
   "source": [
    "i, j = tok2idx['end'], tok2idx['the']\n",
    "pmi1 = pmi_1(mat)\n",
    "print('Unigram sum method: The PMI normalization score of words \"the\" and \"end\" is: ', float(pmi1[j][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luyin/anaconda3/envs/nlps/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in true_divide\n",
      "/Users/luyin/anaconda3/envs/nlps/lib/python3.6/site-packages/ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix sum method: The PMI normalization score of words \"the\" and \"end\" is:  2.1189804794420937\n"
     ]
    }
   ],
   "source": [
    "pmi2 = pmi_2(mat)\n",
    "print('Matrix sum method: The PMI normalization score of words \"the\" and \"end\" is: ', float(pmi2[j][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second PMI method is straight-forward and directly works on the matrix itself. The PPMI is calculated based on this method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__b__. We also consider an extension of PMI, positive PMI (PPMI), that maps all negative PMI values to 0.0 ([Levy and Goldberg 2014](http://papers.nips.cc/paper/5477-neural-word-embedding-as-implicit-matrix-factorization)). \n",
    "Write `ppmi`, which is the same as `pmi` except it applies PPMI instead of PMI (feel free to implement it as an option of `pmi`). What is the PMI of the words \"the\" and \"start\"? The PPMI? [5 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppmi(mat):\n",
    "    \"\"\"Pointwise mutual information\n",
    "    \n",
    "    args:\n",
    "        - mat: 2d np.array to apply PMI\n",
    "        \n",
    "    returns:\n",
    "        - ppmi_mat: matrix of same shape with PMI applied\n",
    "    \"\"\"    \n",
    "#     np.fill_diagonal(mat, 0)\n",
    "    total_sum = mat.sum()\n",
    "    \n",
    "    mat = mat/total_sum\n",
    "    #row sum of matrix\n",
    "    row_s = mat.sum(axis = 1)\n",
    "    #column sum of matrix\n",
    "    col_s = mat.sum(axis = 0)\n",
    "    \n",
    "    s1 = mat/col_s\n",
    "    s2 = s1/row_s[:, np.newaxis]\n",
    "    #change the 0 input as 1 so that log(1) = 0\n",
    "    s2[s2 == 0] = 1\n",
    "    #If s2 is negative, manual change it to 1 so that log(s2) =0\n",
    "    s2[s2 < 1] = 1\n",
    "    return np.log(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luyin/anaconda3/envs/nlps/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in true_divide\n",
      "/Users/luyin/anaconda3/envs/nlps/lib/python3.6/site-packages/ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in true_divide\n",
      "/Users/luyin/anaconda3/envs/nlps/lib/python3.6/site-packages/ipykernel_launcher.py:23: RuntimeWarning: invalid value encountered in less\n"
     ]
    }
   ],
   "source": [
    "ppmi_1 = ppmi(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The PMI normalization score of words \"the\" and \"start\" is:  0.2921512782120165\n",
      "The PPMI normalization score of words \"the\" and \"start\" is:  0.2921512782120165\n"
     ]
    }
   ],
   "source": [
    "i, j = tok2idx['the'], tok2idx['start']\n",
    "pmi = pmi_2(mat)\n",
    "ppmi_1 = ppmi(mat)\n",
    "print('The PMI normalization score of words \"the\" and \"start\" is: ', float(pmi[j][i]))\n",
    "print('The PPMI normalization score of words \"the\" and \"start\" is: ', float(ppmi_1[j][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PMI and PPMI scores are same probably because there is not negative element in current matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyzing PMI [25 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__a__. Consider the matrix `np.array([[1.0, 0.0, 0.0], [1000.0, 1000.0, 4000.0], [1000.0, 2000.0, 999.0]])`. Reweight this matrix using `ppmi`. (i) What is the value obtained for cell `[0,0]`, and (ii) give a brief description for what is likely problematic about this value. [10 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.60893804, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.28788209],\n",
       "       [0.22289371, 0.51107566, 0.        ]])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat2 = np.array([[1.0, 0.0, 0.0], [1000.0, 1000.0, 4000.0], [1000.0, 2000.0, 999.0]])\n",
    "ppmi(mat2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. The value of cell [0,0] is 1.60893804\n",
    "\n",
    "ii. The value is nomalized higher than its previous value (from 1 to 1.6) because of other large elements. After normalization, large value like 1000 is normalized to 0. Thus, PMI tends to normalize infrequent elements larger. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__b__. Give a suggestion for dealing with the problematic value and explain why it deals with this. Demonstrate your suggestion empirically [10 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One possible solutioin is to use the similar idea of Laplace smoothing. Adding a small constant m to each count before the PMI normalization process. For example, after adding 3 to 1 and 1000, the relative ratio between 1000 and 1 which is 1000 (1000/1) is now changed to 250.75 (1003/4). The larger value is indirectly discounted by adding constant, with a larger constant m, the discount effect is stronger for large values. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__c__. Consider starting with a word-word co-occurence matrix and applied PMI to this matrix. (i) Which of the following describe the resulting vectors: sparse, dense, high-dimensional, low-dimensional (ii) If you wanted the opposite style of representation, what could you do? [5 pts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.69843176,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  1.95499042],\n",
       "       [ 0.        ,  2.02258584, -0.88402636, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        , -0.88402636,  2.16160906, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ..., 10.41403647,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "        10.41403647,  0.        ],\n",
       "       [ 1.95499042,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. The resulting matrix has a high sparsity with many zero values and it is also high in dimensions. One possible solution is to use PCA method to reduce the dimension and sparsity of the matrix. \n",
    "\n",
    "ii. Since the resulting co-occurence matrix is symmetric already, it is good to perform PCA anlaysis and choose the top K features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Word Analogy Evaluation [25 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word analogies provide another kind of evaluation for distributed representations. Here, we are given three vectors A, B, and C, in the relationship\n",
    "\n",
    "_A is to B as C is to __ _\n",
    "\n",
    "and asked to identify the fourth that completes the analogy. These analogies are by and large substantially easier than the classic brain-teaser analogies that used to appear on tests like the SAT, but it's still an interesting, demanding\n",
    "task. \n",
    "\n",
    "The core idea is that we make predictions by creating the vector\n",
    "\n",
    "$$(A - B) + C$$ \n",
    "\n",
    "and then ranking all vectors based on their distance from this new vector, choosing the closest as our prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__a__. Implement the function `analogy_completion`. [9 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy_completion(a, b, c, mat):\n",
    "    \"\"\"Compute ? in \n",
    "    a is to b as c is to ? \n",
    "    as the closest to (b-a) + c\n",
    "    return closest word index and minimum distance\n",
    "    \"\"\"\n",
    "    # calculate the vector\n",
    "    \n",
    "    v = (mat[b]-mat[a]) + mat[c]\n",
    "    min_distance = float('inf')\n",
    "    closest_vc = None\n",
    "    for u in mat:\n",
    "        if u not in (a, b, c): # filter same words that are used in analogy\n",
    "            distance = 1- cosine_similarity(mat[u], v)\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                closest_vc =  u    \n",
    "    return closest_vc, min_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"China\" not in (\"Beijing\", \"good\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__b__. Our simple word embeddings likely won't perform well on this task. Let's instead look at some high quality pretrained word embeddings. Write code to load 300-dimensional [GloVe word embeddings](http://nlp.stanford.edu/data/glove.840B.300d.zip) trained on 840B tokens. Each line of the file is formatted as a word followed by 300 floats that make up its corresponding word embedding (all space delimited). The entries of GloVe word embeddings are not counts, but instead are learned via machine learning. Use your `analogy_completion` code to complete the following analogies using the GloVe word embeddings. [6 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \"Beijing\" is to \"China\" as \"Paris\" is to ?\n",
    "- \"gold\" is to \"first\" as \"silver\" is to ?\n",
    "- \"Italian\" is to \"mozzarella\" as \"American\" is to ?\n",
    "- \"research\" is to \"fun\" as \"engineering\" is to ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove(glove_file, n_vecs=20000):\n",
    "    \"\"\" \"\"\"\n",
    "    tok2vec = {}\n",
    "    with open(glove_file, 'r') as glove_fh:\n",
    "        for i, row in enumerate(glove_fh):\n",
    "            word, vec = row.split(' ', 1)\n",
    "            tok2vec[word] = np.array([float(n) for n in vec.split(' ')])\n",
    "            if i >= n_vecs:\n",
    "                break\n",
    "    return tok2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file = \"glove.840B.300d.txt\"\n",
    "glove_vecs = load_glove(glove_file, n_vecs=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_analogy(word1, word2, word3, mat):\n",
    "    output, distance = analogy_completion(word1, word2, word3, mat)\n",
    "    print('\"%s\" is to \"%s\" as %s\" to \"%s\"' % (word1, word2, word3, output))\n",
    "    print('The minimum distance is: ', distance)\n",
    "    return output, distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Beijing\" is to \"China\" as Paris\" to \"France\"\n",
      "The minimum distance is:  0.27706330530641043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('France', 0.27706330530641043)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_analogy('Beijing', 'China', 'Paris', glove_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"gold\" is to \"first\" as silver\" to \"second\"\n",
      "The minimum distance is:  0.3024389409663598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('second', 0.3024389409663598)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_analogy('gold', 'first', 'silver', glove_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Italian\" is to \"mozzarella\" as American\" to \"cheddar\"\n",
      "The minimum distance is:  0.4171742770336405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('cheddar', 0.4171742770336405)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_analogy('Italian', \"mozzarella\", \"American\", glove_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"research\" is to \"fun\" as engineering\" to \"awesome\"\n",
      "The minimum distance is:  0.5027277614731709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('awesome', 0.5027277614731709)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_analogy(\"research\", \"fun\", \"engineering\", glove_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Let's get a more quantitative, aggregate sense of the quality of GloVe embeddings. Load the analogies from `gram6-nationality-adjective.txt` and evaluate GloVe embeddings. Report the mean reciprocal rank of the correct answer (the last word on each line) for each analogy. [10 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Solution__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_analogy_file(test_file):\n",
    "    input_words = []\n",
    "    true_words = []\n",
    "    with open(test_file, 'r') as analogy_file:\n",
    "        rows = [line.rstrip('\\n') for line in analogy_file]\n",
    "        for row in rows:\n",
    "            words = row.split(' ')\n",
    "            input_words.append(words[:3])\n",
    "            true_words.append(words[-1])\n",
    "    return input_words, true_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['France',\n",
       " 'French',\n",
       " 'Europe',\n",
       " 'Pierre',\n",
       " 'Le',\n",
       " 'Jean',\n",
       " 'paris',\n",
       " 'FRANCE',\n",
       " 'PARIS',\n",
       " 'france',\n",
       " 'Italy',\n",
       " 'Belgium',\n",
       " 'du',\n",
       " 'Luxembourg',\n",
       " 'Provence']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analogy_completion_list(a, b, c, mat):\n",
    "    \"\"\"Compute ? in \n",
    "    a is to b as c is to ? \n",
    "    \n",
    "    return list of top 15 possible words for analogy \n",
    "    \n",
    "    I make an assumption that the most true words are within the top 15 prediction words\n",
    "    \"\"\"\n",
    "    # calculate the vector\n",
    "    \n",
    "    v = (mat[b]-mat[a]) + mat[c]\n",
    "    \n",
    "    distance_list = []\n",
    "    words_list = []\n",
    "    closest_vc = None\n",
    "    for u in mat:\n",
    "        if u not in (a, b, c):\n",
    "            distance = 1- cosine_similarity(mat[u], v)\n",
    "            distance_list.append(distance)\n",
    "            words_list.append(u)   \n",
    "    result = sorted(zip( distance_list, words_list))\n",
    "    return [line[1] for line in result]\n",
    "\n",
    "analogy_completion_list('Beijing', 'China', 'Paris', glove_vecs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analogy_completion_list('Beijing', 'China', 'Paris', glove_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_list.index('FRANCE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'FRANCH' in test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy_completion_list(a, b, c, mat):\n",
    "    \"\"\"Compute ? in \n",
    "    a is to b as c is to ? \n",
    "    \n",
    "    return list of possible words for analogy prediction\n",
    " \n",
    "    \n",
    "    \"\"\"\n",
    "    # calculate the vector\n",
    "    v = (mat[b]-mat[a]) + mat[c]\n",
    "    \n",
    "    distance_list = []\n",
    "    words_list = []\n",
    "    \n",
    "    for u in mat:\n",
    "        if u not in (a, b, c):\n",
    "            distance = 1- cosine_similarity(mat[u], v)\n",
    "            distance_list.append(distance)\n",
    "            words_list.append(u)  \n",
    "\n",
    "    result = sorted(zip( distance_list, words_list)) # return all closest prediction\n",
    "#   result = sorted(zip( distance_list, words_list))[:15]# return the top 15 closest prediction\n",
    "    return [line[1] for line in result]\n",
    "\n",
    "\n",
    "def mean_reciprocal_rank(true_words, predict_words_list):\n",
    "    \n",
    "    '''\n",
    "    Take list of true words and predict_words_list\n",
    "    \n",
    "    Return mean_reciprocal_rank and the accuracy of the prediction\n",
    "    \n",
    "    '''\n",
    "    rr = 0\n",
    "    correct = 0\n",
    "    for i in range(len(true_words)):\n",
    "        true_word = true_words[i]\n",
    "        predict_words = predict_words_list[i]\n",
    "        if true_word in predict_words:\n",
    "            pos_idx = predict_words.index(true_word)\n",
    "            if pos_idx == 0:\n",
    "                #Calcualte the correctness of the first prediction\n",
    "                correct +=1  \n",
    "            #reciprocal_rank\n",
    "            rr += 1/(pos_idx+1) \n",
    "            \n",
    "    mrr = rr/len(true_words) \n",
    "    return mrr, correct\n",
    "\n",
    "\n",
    "def analogy_evaluation(glove_vecs, test_file, verbose=False):\n",
    "    \"\"\"Basic analogies evaluation for a file `src_filename `\n",
    "    in `question-data/`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------    \n",
    "    mat : 2d np.array\n",
    "        The VSM being evaluated.\n",
    "        \n",
    "    rownames : list of str\n",
    "        The names of the rows in `mat`.\n",
    "        \n",
    "    src_filename : str\n",
    "        Basename of the file to be evaluated. It's assumed to be in\n",
    "        `vsmdata_home`/question-data.\n",
    "        \n",
    "    distfunc : function mapping vector pairs to floats (default: `cosine`)\n",
    "        The measure of distance between vectors. Can also be `euclidean`, \n",
    "        `matching`, `jaccard`, as well as any other distance measure \n",
    "        between 1d vectors.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    (float, float)\n",
    "        The first is the mean reciprocal rank of the predictions and \n",
    "        the second is the accuracy of the predictions.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    input_words, true_words = load_analogy_file(test_file)\n",
    "    predict_words_list = []\n",
    "    existing_true_words = []\n",
    "    \n",
    "    for i in range(len(input_words)):\n",
    "        a,b,c = input_words[i]\n",
    "        if a in glove_vecs and b in glove_vecs and c in glove_vecs and true_words[i] in glove_vecs: # ignore words not in glove\n",
    "            predict_words_list.append(analogy_completion_list(a, b, c, glove_vecs))\n",
    "            existing_true_words.append(true_words[i]) #found the words in glove_vecs\n",
    "            \n",
    "    mrr, correct = mean_reciprocal_rank(existing_true_words, predict_words_list)\n",
    "    \n",
    "    return mrr, (correct/len(existing_true_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9526251526251527, 0.9358974358974359)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get top 15 predictions for each analogy and ignore all 4 words not in glove\n",
    "analogy_evaluation(glove_vecs, \"gram6-nationality-adjective.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7995877163039019, 0.7849462365591398)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all predctions for each analogy and allow true words not in glove\n",
    "analogy_evaluation(glove_vecs, \"gram6-nationality-adjective.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.953354584823883, 0.9358974358974359)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all predictions for each analogy and ignore all 4 words not in glove\n",
    "analogy_evaluation(glove_vecs, \"gram6-nationality-adjective.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocabulary size = 20000 in glove embedding is used for this case:\n",
    "\n",
    "MRR that ignores words(including true word) in glove embedding is around 0.95 with accuracy of 0.93\n",
    "\n",
    "MRR that allows true word not in glove embedding is around 0.8 with accuracy of 0.78, it is possible that if the vocabulary size of glove embedding increase, MRR would be higher in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9391509433962264, defaultdict(int, {True: 97, False: 9}))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy_evaluation(glove_vecs, \"gram6-nationality-adjective.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
